import requests
from bs4 import BeautifulSoup
import json

# Function to fetch and extract descriptions, extended description, relationships, modes of introduction, applicable platforms, common consequences, likelihood of exploit, demonstrative examples, observed examples, potential mitigations, weakness ordinalities, detection methods, functional areas, affected resources, memberships, vulnerability mapping notes, notes, taxonomy mappings, related attack patterns, references, and content history
def fetch_description(url, number):
    response = requests.get(url)
    response.raise_for_status()  # Check for request errors
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # Remove all <span class="tip"> elements
    for tip in soup.find_all('span', class_='tip'):
        tip.decompose()
    
    # Extract description
    description_div = soup.select_one(f"#oc_{number}_Description > div > div")
    description = description_div.get_text(strip=True) if description_div else None

    # Extract extended description (handle multiple paragraphs)
    extended_description_div = soup.select_one(f"#oc_{number}_Extended_Description > div > div")
    extended_description = None
    if extended_description_div:
        paragraphs = extended_description_div.find_all('p')
        if paragraphs:
            extended_description = '\n\n'.join(p.get_text(strip=True) for p in paragraphs)
        else:
            extended_description = extended_description_div.get_text(strip=True)

    # Extract relationships
    relationships_div = soup.select_one("#Relationships")
    relationships = relationships_div.get_text(strip=True).replace("Relationships", "").strip() if relationships_div else None
    
    # Extract modes of introduction
    modes_of_introduction_div = soup.select_one("#Modes_Of_Introduction")
    modes_of_introduction = modes_of_introduction_div.get_text(strip=True).replace("Modes Of Introduction", "").strip() if modes_of_introduction_div else None
    
    # Extract applicable platforms
    applicable_platforms_div = soup.select_one("#Applicable_Platforms")
    applicable_platforms = applicable_platforms_div.get_text(strip=True).replace("Applicable Platforms", "").strip() if applicable_platforms_div else None

    # Extract common consequences
    common_consequences_div = soup.select_one("#Common_Consequences")
    common_consequences = common_consequences_div.get_text(strip=True).replace("Common Consequences", "").strip() if common_consequences_div else None
    
    # Extract likelihood of exploit
    likelihood_of_exploit_div = soup.select_one("#Likelihood_Of_Exploit")
    likelihood_of_exploit = likelihood_of_exploit_div.get_text(strip=True).replace("Likelihood Of Exploit", "").strip() if likelihood_of_exploit_div else None

    # Extract demonstrative examples
    demonstrative_examples_div = soup.select_one("#Demonstrative_Examples")
    demonstrative_examples = demonstrative_examples_div.get_text(strip=True).replace("Demonstrative Examples", "").strip() if demonstrative_examples_div else None

    # Extract observed examples
    observed_examples_div = soup.select_one("#Observed_Examples")
    observed_examples = observed_examples_div.get_text(strip=True).replace("Observed Examples", "").strip() if observed_examples_div else None
    
    # Extract potential mitigations
    potential_mitigations_div = soup.select_one("#Potential_Mitigations")
    potential_mitigations = potential_mitigations_div.get_text(strip=True).replace("Potential Mitigations", "").strip() if potential_mitigations_div else None
    
    # Extract weakness ordinalities
    weakness_ordinalities_div = soup.select_one("#Weakness_Ordinalities")
    weakness_ordinalities = weakness_ordinalities_div.get_text(strip=True).replace("Weakness Ordinalities", "").strip() if weakness_ordinalities_div else None

    # Extract detection methods
    detection_methods_div = soup.select_one("#Detection_Methods")
    detection_methods = detection_methods_div.get_text(strip=True).replace("Detection Methods", "").strip() if detection_methods_div else None

    # Extract functional areas
    functional_areas_div = soup.select_one("#Functional_Areas")
    functional_areas = functional_areas_div.get_text(strip=True).replace("Functional Areas", "").strip() if functional_areas_div else None
    
    # Extract affected resources
    affected_resources_div = soup.select_one("#Affected_Resources")
    affected_resources = affected_resources_div.get_text(strip=True).replace("Affected Resources", "").strip() if affected_resources_div else None

    # Extract memberships
    memberships_div = soup.select_one("#Memberships")
    memberships = memberships_div.get_text(strip=True).replace("Memberships", "").strip() if memberships_div else None
    
    # Extract vulnerability mapping notes
    vulnerability_mapping_notes_div = soup.select_one("#Vulnerability_Mapping_Notes")
    vulnerability_mapping_notes = vulnerability_mapping_notes_div.get_text(strip=True).replace("Vulnerability Mapping Notes", "").strip() if vulnerability_mapping_notes_div else None

    # Extract notes
    notes_div = soup.select_one("#Notes")
    notes = notes_div.get_text(strip=True).replace("Notes", "").strip() if notes_div else None
    
    # Extract taxonomy mappings
    taxonomy_mappings_div = soup.select_one("#Taxonomy_Mappings")
    taxonomy_mappings = taxonomy_mappings_div.get_text(strip=True).replace("Taxonomy Mappings", "").strip() if taxonomy_mappings_div else None
    
    # Extract related attack patterns
    related_attack_patterns_div = soup.select_one("#Related_Attack_Patterns")
    related_attack_patterns = related_attack_patterns_div.get_text(strip=True).replace("Related Attack Patterns", "").strip() if related_attack_patterns_div else None

    # Extract references
    references_div = soup.select_one("#References")
    references = references_div.get_text(strip=True).replace("References", "").strip() if references_div else None

    # Extract content history
    content_history_div = soup.select_one("#Content_History")
    content_history = content_history_div.get_text(strip=True).replace("Content History", "").strip() if content_history_div else None
    
    return (description, extended_description, relationships, modes_of_introduction, applicable_platforms, common_consequences, 
            likelihood_of_exploit, demonstrative_examples, observed_examples, potential_mitigations, weakness_ordinalities, detection_methods, functional_areas, affected_resources, memberships, vulnerability_mapping_notes, notes, taxonomy_mappings, related_attack_patterns, references, content_history)

# Example URL
base_url = "https://cwe.mitre.org/data/definitions/"
suffix = ".html"

numbers = [22]

# Save the description to a JSON file
descriptions = {}

# Fetch the description
for number in numbers:
    url = f"{base_url}{number}{suffix}"
    (description, extended_description, relationships, modes_of_introduction, applicable_platforms, common_consequences, 
     likelihood_of_exploit, demonstrative_examples, observed_examples, potential_mitigations, weakness_ordinalities, detection_methods, functional_areas, affected_resources, memberships, vulnerability_mapping_notes, notes, taxonomy_mappings, related_attack_patterns, references, content_history) = fetch_description(url, number)
    descriptions[f"CWE-{number}"] = {
        "Description": description,
        "Extended Description": extended_description,
        "Relationships": relationships,
        "Modes Of Introduction": modes_of_introduction,
        "Applicable Platforms": applicable_platforms,
        "Common Consequences": common_consequences,
        "Likelihood Of Exploit": likelihood_of_exploit,
        "Demonstrative Examples": demonstrative_examples,
        "Observed Examples": observed_examples,
        "Potential Mitigations": potential_mitigations,
        "Weakness Ordinalities": weakness_ordinalities,
        "Detection Methods": detection_methods,
        "Functional Areas": functional_areas,
        "Affected Resources": affected_resources,
        "Memberships": memberships,
        "Vulnerability Mapping Notes": vulnerability_mapping_notes,
        "Notes": notes,
        "Taxonomy Mappings": taxonomy_mappings,
        "Related Attack Patterns": related_attack_patterns,
        "References": references,
        "Content History": content_history
    }

with open('description.json', 'w') as json_file:
    json.dump(descriptions, json_file, indent=4)

print("Descriptions saved to description.json")
